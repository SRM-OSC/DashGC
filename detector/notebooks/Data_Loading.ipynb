{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLBZYNndfnEy",
        "colab_type": "text"
      },
      "source": [
        "# Pre Run Checks\n",
        " - Change runtime to **python3** with **GPU** Accelerator\n",
        " - Change default indent to **4** instead of **2**\n",
        " - Use **Dark theme** with **line numbers enabled** for your _sanity_\n",
        " - Logged in with **college** ID which contains the _reorganised_ dataset in the **Google Drive**\n",
        " - Check the _**decompression cell**_ & _**training cell**_ for **path** validity to the folder containing the compressed dataset\n",
        " - Get something ready to do for **10 mins** like _drinking coffee_ or turning on _**kitty mode**_ in _tools -> preferences -> misc_ to pass the time while it decompresses the dataset\n",
        " - Now run it & enjoy your coffee (or whatever is your poison)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cHejutAfcAb",
        "colab_type": "code",
        "outputId": "cf794c72-7152-4bb9-d1ca-686ce3a07c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!pip install -U pip\n",
        "!pip install tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.2.3)\n",
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 28kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow-gpu==2.0.0-rc1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 24.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.16.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.1.7)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow-gpu==2.0.0-rc1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.11.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (0.15.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (41.2.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgyzFo2hf9Be",
        "colab_type": "code",
        "outputId": "583b3f2e-62e9-4bff-d260-2ef913f3a450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "tf.random.set_seed(13) # Just a random seed for tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiXj6hyegMTJ",
        "colab_type": "code",
        "outputId": "c566570a-e77f-43de-9f81-a07efb5499c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Decompress the compressed reorganized \"Jester\" dataset in Google Colab VM\n",
        "\n",
        "start = time.time()\n",
        "!cat /content/gdrive/My\\ Drive/DashGC/Reorganized/Dataset.tar.gz.?? | tar -xz\n",
        "stop = time.time()\n",
        "print('Decompression took', round(((stop - start) / 60), 2), 'mins')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decompression took 11.38 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhw1GaERgVYu",
        "colab_type": "code",
        "outputId": "4be22243-ab95-493a-e2e0-6ffa18d046c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Use Pathlib to get the path root to the dataset\n",
        "\n",
        "train_data_root_orig = \"./Dataset/Train\"\n",
        "train_data_root = pathlib.Path(train_data_root_orig)\n",
        "print(train_data_root)\n",
        "\n",
        "val_data_root_orig = \"./Dataset/Validation\"\n",
        "val_data_root = pathlib.Path(val_data_root_orig)\n",
        "print(val_data_root)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset/Train\n",
            "Dataset/Validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DMi_qmPgtVS",
        "colab_type": "code",
        "outputId": "66bf97ff-3390-4c32-efd3-1412ddc3a849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Sorting path list by filename (aka frame id) [first] & directory name (aka video id) [second sort key]\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "val_image_paths = list(val_data_root.glob('*/*/*'))\n",
        "# val_image_paths = [str(path) for path in val_image_paths]\n",
        "val_image_paths = list(map(lambda x: str(x), val_image_paths))\n",
        "val_image_paths.sort(key = lambda x: (int(x.split('/')[-1][:-5]), int(x.split('/')[-2])))\n",
        "# val_image_paths = list(map(lambda s: pathlib.Path(s), val_image_paths))\n",
        "\n",
        "train_image_paths = list(train_data_root.glob('*/*/*'))\n",
        "# train_image_paths = [str(path) for path in train_image_paths]\n",
        "train_image_paths = list(map(lambda x: str(x), train_image_paths))\n",
        "train_image_paths.sort(key = lambda x: (int(x.split('/')[-1][:-5]), int(x.split('/')[-2])))\n",
        "# train_image_paths = list(map(lambda s: pathlib.Path(s), train_image_paths))\n",
        "\n",
        "stop = time.time()\n",
        "print('Sorting took', round(((stop - start) / 60), 2), 'mins')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sorting took 1.09 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "729fb171-0cd3-4052-c8e7-258a28514bb1",
        "id": "okktuZZpND4C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(type(train_image_paths[0]), train_image_paths[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'> Dataset/Train/Doing other things/1/00003.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lyZid1RjMVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Indexing of classification class labels\n",
        "\n",
        "label_names = sorted(item.name for item in train_data_root.glob('*/') if item.is_dir())\n",
        "label_to_index = {name: index for index, name in enumerate(label_names)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUWaDdBRjz8u",
        "colab_type": "code",
        "outputId": "e51a768c-b3e4-4a1a-e9f7-13f7b97dd9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Stores the label index for each video\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# train_image_labels = [label_to_index[pathlib.Path(path).parent.parent.name]\n",
        "                    # for path in train_image_paths]\n",
        "\n",
        "train_image_labels = list(map(lambda p: label_to_index[pathlib.Path(p).parent.parent.name], train_image_paths))\n",
        "\n",
        "# val_image_labels = [label_to_index[pathlib.Path(path).parent.parent.name]\n",
        "                    # for path in val_image_paths]\n",
        "\n",
        "val_image_labels = list(map(lambda p: label_to_index[pathlib.Path(p).parent.parent.name], val_image_paths))\n",
        "\n",
        "stop = time.time()\n",
        "print('Labeling took', round(((stop - start) / 60), 2), 'mins') # 0.69 mins"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labeling took 0.67 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XgVIQQnj328",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decode the video frames as int64 values of color & recast it as float32\n",
        "# Resize the video frames into a squared size (100, 100, channels = 3)\n",
        "\n",
        "#@tf.function\n",
        "def preprocess_image(image):\n",
        "    '''\n",
        "    Decodes the binary form to normalized vector (aka tensor) form\n",
        "    '''\n",
        "    # image = tf.image.decode_image(image, channels=3)\n",
        "    image = tf.image.decode_jpeg(image, channels=3) # imports RGB channels, jpeg doesn't have a 4th channel alpha for transparency like png\n",
        "    image = tf.image.resize(image, [100, 100]) # original dimensions are (100, 176) (height, width)\n",
        "    image /= 255.0  # normalize to [0,1] range using broadcast method\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    '''\n",
        "    Open the file from path as binary\n",
        "    '''\n",
        "    image = tf.io.read_file(path)\n",
        "    return preprocess_image(image)\n",
        "\n",
        "def load_and_preprocess_from_path_label(path, label):\n",
        "    return load_and_preprocess_image(path), label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9ev8pUOkgrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the images as tensors (numpy-like multidimensional arrays)\n",
        "\n",
        "train_path_ds = tf.data.Dataset.from_tensor_slices(train_image_paths)\n",
        "train_image_ds = train_path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24fVPDn7SAqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_path_ds = tf.data.Dataset.from_tensor_slices(val_image_paths)\n",
        "val_image_ds = val_path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "002AhJSSRiiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Labeling\n",
        "\n",
        "train_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(train_image_labels, tf.int8))\n",
        "val_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(val_image_labels, tf.int8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLpkXc1nnOvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset Generator [WIP] [TODO]\n",
        "\n",
        "train_image_label_ds = tf.data.Dataset.from_generator((pair for pair in zip(train_image_ds, train_label_ds)))\n",
        "val_image_label_ds = tf.data.Dataset.from_generator((pair for pair in zip(val_image_ds, val_label_ds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYYkOjQ3Rkvs",
        "colab_type": "code",
        "outputId": "9c2d79c8-c6d1-4d75-eaed-3e7e052f6a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Dataset Generator [WIP] [TODO]\n",
        "\n",
        "#train_image_label_ds = tf.data.Dataset.from_generator((pair for pair in zip(list(map(load_and_preprocess_image, train_image_paths)), train_label_ds)))\n",
        "val_image_label_ds = tf.data.Dataset.from_generator((pair for pair in zip(list(map(load_and_preprocess_image, val_image_paths)), val_label_ds)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4af294af7325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_image_label_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_image_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-bcfd9a3d1f8e>\u001b[0m in \u001b[0;36mload_and_preprocess_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     14\u001b[0m     '''\n\u001b[1;32m     15\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_preprocess_from_path_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-bcfd9a3d1f8e>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# imports RGB channels, jpeg doesn't have a 4th channel alpha for transparency like png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# original dimensions are (100, 176) (height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.0\u001b[0m  \u001b[0;31m# normalize to [0,1] range using broadcast method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    910\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1003\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   7948\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7949\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7950\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7951\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7952\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[100,100,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RealDiv] name: truediv/"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYDP1VEVV7m-",
        "colab_type": "text"
      },
      "source": [
        "# Model \n",
        "The code following this block is to be customised for experimentation, testing & evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmEcy0USwM5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train_image_ds\n",
        "X_val = val_image_ds\n",
        "\n",
        "Y_train = train_label_ds\n",
        "Y_val = val_label_ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awXyN7KKQ-px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [WIP] [TODO]\n",
        "\n",
        "def cnn_block(X, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the CNN block as defined\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the custom block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3, F4, F5 = filters\n",
        "\n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = tf.keras.layers.Conv2D(filters=F1, kernel_size=(3, 3), strides=(1, 1), padding='same', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "    X = tf.keras.layers.Conv2D(filters=F2, kernel_size=(3, 3), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "    X = tf.keras.layers.SpatialDropout2D(0.2)(X)\n",
        "    X = tf.keras.layers.MaxPooling2D((2, 2), name='max_pool0')(X)\n",
        "\n",
        "    # Second component of main path (≈2 lines)\n",
        "    X = tf.keras.layers.Conv2D(filters=F3, kernel_size=(3, 3), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "    X = tf.keras.layers.MaxPooling2D((2, 2), name='max_pool1')(X)\n",
        "\n",
        "    X = tf.keras.layers.Conv2D(filters=F4, kernel_size=(3, 3), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2d')(X)\n",
        "    X = tf.keras.layers.MaxPooling2D((2, 2), name='max_pool2')(X)\n",
        "\n",
        "    X = tf.keras.layers.Conv2D(filters=F5, kernel_size=(3, 3), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2e')(X)\n",
        "    X = tf.keras.layers.SpatialDropout2D(0.2)(X)\n",
        "    X = tf.keras.layers.MaxPooling2D((2, 2), name='max_pool3')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
        "    X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jHODosiw76V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [WIP] [TODO]\n",
        "def LSTM_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the ConvLSTM block as defined\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the custom block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZURfzhaOYW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Definition using Keras Functional API\n",
        "\n",
        "def model(input_shape):\n",
        "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
        "    X_input = tf.keras.Input(input_shape)\n",
        "\n",
        "    # Zero-Padding: pads the border of X_input with zeroes\n",
        "    # X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    X = cnn_block(X_input, (1024, 512, 512, 256, 128), 0, \"input_cnn\")\n",
        "\n",
        "    X = LSTM_block(X, 3, (128, 128, 64, 64, 32), 1, \"output_lstm\")\n",
        "\n",
        "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
        "    X = tf.keras.layers.Flatten()(X)\n",
        "    X = tf.keras.layers.Dense(1, activation='softmax', name='fc')(X)\n",
        "\n",
        "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
        "    model = tf.keras.Model(inputs = X_input, outputs = X, name='test0')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMHT8eiuWOpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the model\n",
        "\n",
        "dummy = model(input_shape=(100, 100, 3))\n",
        "\n",
        "# Compile the model\n",
        "dummy.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy', 'categorical_accuracy']\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBm_oTpAX1_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the model on the Dataset\n",
        "\n",
        "history = dummy.fit(x=X_train,\n",
        "                    y=Y_train,\n",
        "                    batch_size=70,\n",
        "                    epochs=20,\n",
        "                    callbacks=tf.keras.callbacks.ModelCheckpoint(filepath='/content/gdrive/My Drive/DashGC/Reorganized/saved_models',\n",
        "                                                                 monitor='val_loss',\n",
        "                                                                 save_best_only=True,\n",
        "                                                                 save_weights_only=False # Since we don't have a storage problem yet\n",
        "                                                                 ),\n",
        "                    validation_data=(X_val, Y_val)\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRgMw5bSMw1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}